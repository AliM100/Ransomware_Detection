{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXgZ5xpUHLK3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOda9uYjQm4R"
      },
      "outputs": [],
      "source": [
        "!git clone 'https://github.com/AliM100/Ransomware_Detection.git'\n",
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doyaiCPqHGYt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import os\n",
        "from math import log\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import patoolib\n",
        "import seaborn as sns\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from datetime import datetime\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import average_precision_score\n",
        "import tensorflow\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torchvision.models import wide_resnet50_2\n",
        "from keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from mal_dataset import maldataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# from Ransomware_Detection.data_conversion import convert_data\n",
        "# from Ransomware_Detection.dataset import load_data,prepare_data\n",
        "# from Ransomware_Detection.pre_act_resnet_model import PreActResNet18,PreActResNet34,PreActResNet50,PreActResNet101,PreActResNet152\n",
        "\n",
        "from data_conversion import convert_data\n",
        "from dataset import load_data,prepare_data\n",
        "from pre_act_resnet_model import PreActResNet18,PreActResNet34,PreActResNet50,PreActResNet101,PreActResNet152\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw1ODRTFg3kf"
      },
      "outputs": [],
      "source": [
        "!wget -O malevis.zip \"https://storage.googleapis.com/kaggle-data-sets/2891213/4985091/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240121%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240121T181109Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4f426a189381f3b6b5b5bc6dbe5704b482810fac67c64801b8d4470c7b21323035206ec5daadf809d65ada4d83504398b5469cd6e63d2d6f787e6f726b196635045c8a5e3d8eac15cf243cc53e43df4b952595f9119f36a1727f94ca9d12fa984b04dc75ce5383c9ba02e87831d36bae3bb56667436336bcf83f2dd5d65edd001dd3b53cc7e6e9a30b566495eea7cf9df9d17dcac9d6b63a3dd9b67874c48748d969cb53a4204d8cbadf4c3d35143c5a4ca0add47dff99286ffdeaaddb8012091730532a114f7f83d4bc180f25b84866bdad0eabd72ebe4cbf5f8f7bbedf439f23b1e814ecca64d93e40bf50c009df828b3a68e2b5feb76480aab6e5853eb2fc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Y-0HSHkN5c"
      },
      "outputs": [],
      "source": [
        "!unzip malevis.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGtwgKseHJif"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/malimg_dataset.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qO82vGtHn6_"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/Benign/\" \"/content/data/malimg_paper_dataset_imgs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPMJptrSAv3"
      },
      "source": [
        "**Optional**\n",
        "Download and preprocess Benign Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I88GrAkg-ce"
      },
      "outputs": [],
      "source": [
        "!wget \"https://figshare.com/ndownloader/files/12149696\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM9IugKqjgM2"
      },
      "outputs": [],
      "source": [
        "patoolib.extract_archive(\"12149696\", outdir=\"Benign_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMiEdyvekpyt"
      },
      "outputs": [],
      "source": [
        "pe_data_path = \"/content/benign_data/benign\"\n",
        "bytes_data_path = \"/content/benign_data/benign_bytes\"\n",
        "img_data_path = \"/content/benign_data/benign_imgs\"\n",
        "csv_data_path = \"/content/benign_data/data.csv\"\n",
        "os.makedirs(pe_data_path,exist_ok=True)\n",
        "os.makedirs(bytes_data_path,exist_ok=True)\n",
        "os.makedirs(img_data_path,exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "dike_dataset=\"Benign_dataset/Dataset/Benign\"\n",
        "\n",
        "\n",
        "for i in os.listdir(dike_dataset):\n",
        "  for j in os.listdir(os.path.join(dike_dataset,i)):\n",
        "    shutil.move(f\"{dike_dataset}/{i}/{j}\",pe_data_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLYH1fKDoBPk"
      },
      "outputs": [],
      "source": [
        "convert_data(pe_data_path,bytes_data_path,img_data_path,csv_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-vyhX_0LXzr"
      },
      "outputs": [],
      "source": [
        "class_index = { 'Adialer.C': 0,\n",
        "                'Adposhel':1,\n",
        "                'Agent.FYI': 2,\n",
        "                'Allaple.A': 3,\n",
        "                'Allaple.L': 4,\n",
        "                'Alueron.gen!J': 5,\n",
        "                'Amonetize':6,\n",
        "                'Androm':7,\n",
        "                'Autorun.K': 8,\n",
        "                'BrowseFox':9,\n",
        "                'C2LOP.P': 10,\n",
        "                'C2LOP.gen!g': 11,\n",
        "                'Dialplatform.B': 12,\n",
        "                'Dinwod':13,\n",
        "                'Dontovo.A': 14,\n",
        "                'Elex':15,\n",
        "                'Expiro':16,\n",
        "                'Fasong':17,\n",
        "                'Fakerean': 18,\n",
        "                'HackKMS':19,\n",
        "                'Hlux':20,\n",
        "                'Injector':21,\n",
        "                'InstallCore':22,\n",
        "                'Instantaccess': 23,\n",
        "                'Lolyda.AA1': 24,\n",
        "                'Lolyda.AA2': 25,\n",
        "                'Lolyda.AA3': 26,\n",
        "                'Lolyda.AT': 27,\n",
        "                'Malex.gen!J': 28,\n",
        "                'MultiPlug':29,\n",
        "                'Neoreklami':30,\n",
        "                'Neshta':31,\n",
        "                'Obfuscator.AD': 32,\n",
        "                'Rbot!gen': 33,\n",
        "                'Regrun': 34,\n",
        "                'Sality':35,\n",
        "                'Skintrim.N': 36,\n",
        "                'Snarasite':37,\n",
        "                'Stantinko':38,\n",
        "                'Swizzor.gen!E': 39,\n",
        "                'Swizzor.gen!I': 40,\n",
        "                'VBA':41,\n",
        "                'VBKrypt':42,\n",
        "                'VB.AT': 43,\n",
        "                'Vilsel':44,\n",
        "                'Wintrim.BX': 45,\n",
        "                'Yuner.A': 46,\n",
        "                'Benign':47}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvW_hrEwHtqQ"
      },
      "outputs": [],
      "source": [
        "class_index = {'Adialer.C': 0,\n",
        "                'Agent.FYI': 1,\n",
        "                'Allaple.A': 2,\n",
        "                'Allaple.L': 3,\n",
        "                'Alueron.gen!J': 4,\n",
        "                'Autorun.K': 5,\n",
        "                'C2LOP.P': 6,\n",
        "                'C2LOP.gen!g': 7,\n",
        "                'Dialplatform.B': 8,\n",
        "                'Dontovo.A': 9,\n",
        "                'Fakerean': 10,\n",
        "                'Instantaccess': 11,\n",
        "                'Lolyda.AA1': 12,\n",
        "                'Lolyda.AA2': 13,\n",
        "                'Lolyda.AA3': 14,\n",
        "                'Lolyda.AT': 15,\n",
        "                'Malex.gen!J': 16,\n",
        "                'Obfuscator.AD': 17,\n",
        "                'Rbot!gen': 18,\n",
        "                'Skintrim.N': 19,\n",
        "                'Swizzor.gen!E': 20,\n",
        "                'Swizzor.gen!I': 21,\n",
        "                'VB.AT': 22,\n",
        "                'Wintrim.BX': 23,\n",
        "                'Yuner.A': 24,\n",
        "                'Benign':25}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0qzB956uonp"
      },
      "outputs": [],
      "source": [
        "data_path=\"data\"\n",
        "malevis_data_path=\"malevis_train_val_300x300\"\n",
        "img_path=\"data/malimg_paper_dataset_imgs\"\n",
        "data_csvs=\"data/csvs\"\n",
        "save_checkpoints_path=\"data/checkpoint\"\n",
        "batch_size=4\n",
        "\n",
        "os.makedirs(save_checkpoints_path,exist_ok=True)\n",
        "os.makedirs(data_csvs,exist_ok=True)\n",
        "\n",
        "data_prepare=prepare_data(data_path,img_path,class_index)\n",
        "#combining MalImg and Malevis datasets\n",
        "# data_prepare.combine_datasets(malevis_data_path)\n",
        "if not os.path.exists(f\"{data_csvs}/train.csv\"):\n",
        "    data_prepare.create_csv_data()\n",
        "\n",
        "target_size_custom = (224, 224)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "training_set=maldataset(csv_file=f\"{data_csvs}/train.csv\",root_dir=img_path, class_index=class_index, transform=transforms.Compose([transforms.Resize(target_size_custom)]))\n",
        "validation_set=maldataset(csv_file=f\"{data_csvs}/val.csv\",root_dir=img_path, class_index=class_index, transform=transforms.Compose([transforms.Resize(target_size_custom)]))\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "classes = ('Adialer.C','Agent.FYI','Allaple.A','Allaple.L','Alueron.gen!J','Autorun.K','C2LOP.P','C2LOP.gen!g','Dialplatform.B','Dontovo.A',\n",
        "           'Fakerean','Instantaccess','Lolyda.AA1','Lolyda.AA2','Lolyda.AA3','Lolyda.AT','Malex.gen!J','Obfuscator.AD','Rbot!gen','Skintrim.N',\n",
        "           'Swizzor.gen!E','Swizzor.gen!I','VB.AT','Wintrim.BX','Yuner.A')\n",
        "\n",
        "# classes = ( 'Adialer.C','Adposhel','Agent.FYI','Allaple.A','Allaple.L','Alueron.gen!J','Amonetize','Androm','Autorun.K','BrowseFox','C2LOP.P',\n",
        "#            'C2LOP.gen!g','Dialplatform.B','Dinwod','Dontovo.A','Elex','Expiro','Fasong','Fakerean','HackKMS','Hlux','Injector','InstallCore',\n",
        "#            'Instantaccess','Lolyda.AA1','Lolyda.AA2','Lolyda.AA3','Lolyda.AT','Malex.gen!J','MultiPlug','Neoreklami','Neshta','Obfuscator.AD','Rbot!gen',\n",
        "#            'Regrun','Sality','Skintrim.N','Snarasite','Stantinko','Swizzor.gen!E','Swizzor.gen!I','VBA','VBKrypt','VB.AT','Vilsel','Wintrim.BX','Yuner.A','Benign')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K__WEC8HtqQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = PreActResNet34().to(device)\n",
        "model = wide_resnet50_2(weights=\"IMAGENET1K_V2\").to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIyfGnkjHtqR"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs.float())\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxI9-azNHtqR"
      },
      "outputs": [],
      "source": [
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(validation_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pRi7FsMHGYv"
      },
      "outputs": [],
      "source": [
        "def test(test_gen,save_checkpoints_path):\n",
        "\n",
        "    model=load_model(f\"{save_checkpoints_path}/model.h5\")\n",
        "\n",
        "    y_pred=model.predict(test_gen)\n",
        "    y_test_predicted = np.argmax(np.array(y_pred),axis = 1)\n",
        "    return y_test_predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elPnQszxHGYv"
      },
      "outputs": [],
      "source": [
        "training_set=maldataset(csv_file=f\"{data_csvs}/test.csv\",root_dir=img_path, class_index=class_index, transform=transforms.Compose([transforms.Resize(target_size_custom)]))\n",
        "test_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "running_testloss=0.0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        inputs, y_gt = inputs.to(device), labels.to(device)\n",
        "\n",
        "        y_test_predicted = model(inputs)\n",
        "        test_loss = loss_fn(y_test_predicted, y_gt)\n",
        "        running_testloss += test_loss\n",
        "\n",
        "        avg_testloss = running_testloss / (i + 1)\n",
        "        print('LOSS test{}'.format(avg_testloss))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kxnpXkDKHrN"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for i in y_test_predicted:\n",
        "  for key,value in class_index.items():\n",
        "    if value==i:\n",
        "      y_pred.append(key)\n",
        "      break\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXuoVAWMEjAW"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrmVqxrPMUq6"
      },
      "outputs": [],
      "source": [
        "c_matrix = metrics.confusion_matrix(test_gen.classes, y_test_predicted)\n",
        "df_confusion = pd.crosstab(test_gen.classes, y_test_predicted)\n",
        "df_confusion.to_csv(os.path.join(data_path,\"confusion_matrix.csv\"))\n",
        "\n",
        "confusion_matrix(c_matrix, classes, figsize = (20,7), fontsize=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoGj--lVaW6Q"
      },
      "outputs": [],
      "source": [
        "accuracy=metrics.accuracy_score(test_gen.classes, y_test_predicted)\n",
        "print(\"accuracy\",accuracy)\n",
        "\n",
        "IoU=metrics.jaccard_score(test_gen.classes, y_test_predicted,average=\"micro\")\n",
        "f1=metrics.f1_score(test_gen.classes, y_test_predicted,average=\"micro\")\n",
        "print(\"micro IoU\",IoU)\n",
        "print(\"micro f1\",f1)\n",
        "\n",
        "IoU=metrics.jaccard_score(test_gen.classes, y_test_predicted,average=\"macro\")\n",
        "f1=metrics.f1_score(test_gen.classes, y_test_predicted,average=\"macro\")\n",
        "print(\"macro IoU\",IoU)\n",
        "print(\"macro f1\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5T2flBwack9"
      },
      "outputs": [],
      "source": [
        "report = metrics.classification_report(test_gen.classes, y_test_predicted, target_names=classes,  output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "print(df_report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
