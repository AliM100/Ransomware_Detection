{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXgZ5xpUHLK3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOda9uYjQm4R"
      },
      "outputs": [],
      "source": [
        "!git clone 'https://github.com/AliM100/Ransomware_Detection.git'\n",
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doyaiCPqHGYt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import os\n",
        "from math import log\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import patoolib\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import average_precision_score\n",
        "import tensorflow\n",
        "from keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from Ransomware_Detection.data_conversion import convert_data\n",
        "from Ransomware_Detection.dataset import load_data,prepare_data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# from Ransomware_Detection.model import build_model\n",
        "# from Ransomware_Detection.resnet_model import build_model\n",
        "from Ransomware_Detection.cus_model import get_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw1ODRTFg3kf"
      },
      "outputs": [],
      "source": [
        "!wget -O malevis.zip \"https://storage.googleapis.com/kaggle-data-sets/2891213/4985091/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240121%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240121T181109Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=4f426a189381f3b6b5b5bc6dbe5704b482810fac67c64801b8d4470c7b21323035206ec5daadf809d65ada4d83504398b5469cd6e63d2d6f787e6f726b196635045c8a5e3d8eac15cf243cc53e43df4b952595f9119f36a1727f94ca9d12fa984b04dc75ce5383c9ba02e87831d36bae3bb56667436336bcf83f2dd5d65edd001dd3b53cc7e6e9a30b566495eea7cf9df9d17dcac9d6b63a3dd9b67874c48748d969cb53a4204d8cbadf4c3d35143c5a4ca0add47dff99286ffdeaaddb8012091730532a114f7f83d4bc180f25b84866bdad0eabd72ebe4cbf5f8f7bbedf439f23b1e814ecca64d93e40bf50c009df828b3a68e2b5feb76480aab6e5853eb2fc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Y-0HSHkN5c"
      },
      "outputs": [],
      "source": [
        "!unzip malevis.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGtwgKseHJif"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/malimg_dataset.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qO82vGtHn6_"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/Benign/\" \"/content/data/malimg_paper_dataset_imgs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWPMJptrSAv3"
      },
      "source": [
        "**Optional**\n",
        "Download and preprocess Benign Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I88GrAkg-ce"
      },
      "outputs": [],
      "source": [
        "!wget \"https://figshare.com/ndownloader/files/12149696\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM9IugKqjgM2"
      },
      "outputs": [],
      "source": [
        "patoolib.extract_archive(\"12149696\", outdir=\"Benign_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMiEdyvekpyt"
      },
      "outputs": [],
      "source": [
        "pe_data_path = \"/content/benign_data/benign\"\n",
        "bytes_data_path = \"/content/benign_data/benign_bytes\"\n",
        "img_data_path = \"/content/benign_data/benign_imgs\"\n",
        "csv_data_path = \"/content/benign_data/data.csv\"\n",
        "os.makedirs(pe_data_path,exist_ok=True)\n",
        "os.makedirs(bytes_data_path,exist_ok=True)\n",
        "os.makedirs(img_data_path,exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "dike_dataset=\"Benign_dataset/Dataset/Benign\"\n",
        "\n",
        "\n",
        "for i in os.listdir(dike_dataset):\n",
        "  for j in os.listdir(os.path.join(dike_dataset,i)):\n",
        "    shutil.move(f\"{dike_dataset}/{i}/{j}\",pe_data_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLYH1fKDoBPk"
      },
      "outputs": [],
      "source": [
        "convert_data(pe_data_path,bytes_data_path,img_data_path,csv_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-vyhX_0LXzr"
      },
      "outputs": [],
      "source": [
        "class_index = { 'Adialer.C': 0,\n",
        "                'Adposhel':1,\n",
        "                'Agent.FYI': 2,\n",
        "                'Allaple.A': 3,\n",
        "                'Allaple.L': 4,\n",
        "                'Alueron.gen!J': 5,\n",
        "                'Amonetize':6,\n",
        "                'Androm':7,\n",
        "                'Autorun.K': 8,\n",
        "                'BrowseFox':9,\n",
        "                'C2LOP.P': 10,\n",
        "                'C2LOP.gen!g': 11,\n",
        "                'Dialplatform.B': 12,\n",
        "                'Dinwod':13,\n",
        "                'Dontovo.A': 14,\n",
        "                'Elex':15,\n",
        "                'Expiro':16,\n",
        "                'Fasong':17,\n",
        "                'Fakerean': 18,\n",
        "                'HackKMS':19,\n",
        "                'Hlux':20,\n",
        "                'Injector':21,\n",
        "                'InstallCore':22,\n",
        "                'Instantaccess': 23,\n",
        "                'Lolyda.AA1': 24,\n",
        "                'Lolyda.AA2': 25,\n",
        "                'Lolyda.AA3': 26,\n",
        "                'Lolyda.AT': 27,\n",
        "                'Malex.gen!J': 28,\n",
        "                'MultiPlug':29,\n",
        "                'Neoreklami':30,\n",
        "                'Neshta':31,\n",
        "                'Obfuscator.AD': 32,\n",
        "                'Rbot!gen': 33,\n",
        "                'Regrun': 34,\n",
        "                'Sality':35,\n",
        "                'Skintrim.N': 36,\n",
        "                'Snarasite':37,\n",
        "                'Stantinko':38,\n",
        "                'Swizzor.gen!E': 39,\n",
        "                'Swizzor.gen!I': 40,\n",
        "                'VBA':41,\n",
        "                'VBKrypt':42,\n",
        "                'VB.AT': 43,\n",
        "                'Vilsel':44,\n",
        "                'Wintrim.BX': 45,\n",
        "                'Yuner.A': 46,\n",
        "                'Benign':47}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxKqkHzeHGYu"
      },
      "outputs": [],
      "source": [
        "def train(train_gen,val_gen,target_size_custom,input_shape,save_checkpoints_path,batch_size, epochs):\n",
        "\n",
        "\n",
        "    resnet = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224,224,3)\n",
        "    )\n",
        "\n",
        "    # efficientnet=tensorflow.keras.applications.efficientnet.EfficientNetB3(\n",
        "    # include_top=False,\n",
        "    # weights='imagenet',\n",
        "    # input_shape=(224,224,3)\n",
        "    # )\n",
        "\n",
        "    # lr_schedule = tensorflow.keras.optimizers.schedules.ExponentialDecay(\n",
        "    # initial_learning_rate=0.001,\n",
        "    # decay_steps=10000,\n",
        "    # decay_rate=0.9)\n",
        "\n",
        "    # model=build_model(resnet, lr=0.00003 , num_classes=48)\n",
        "    model=get_model(shape=input_shape)\n",
        "    # model=build_model(efficientnet, lr=0.00003 , num_classes=48)\n",
        "\n",
        "    # model = build_model(target_size_custom)\n",
        "\n",
        "    rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, verbose=1, patience=5, min_lr=0.000001)\n",
        "\n",
        "    # X_train, y_train=train_gen.next()\n",
        "    # X_val, y_val= val_gen.next()\n",
        "\n",
        "    # X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "\n",
        "    # X_val_reshaped = X_val.reshape(X_val.shape[0],-1)\n",
        "\n",
        "    # rus = RandomUnderSampler(sampling_strategy='auto',random_state=42)\n",
        "\n",
        "    # X_train_resampled, y_train_resampled = rus.fit_resample(X_train_reshaped, y_train.argmax(axis=1))\n",
        "    # X_val_resampled, y_val_resampled = rus.fit_resample(X_val_reshaped, y_val.argmax(axis=1))\n",
        "\n",
        "    # # Reshape back to 3D (number of samples x image width x image height x channels)\n",
        "    # X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], target_size_custom[0], target_size_custom[1], 3)\n",
        "    # X_val_resampled = X_val_resampled.reshape(X_val_resampled.shape[0], target_size_custom[0], target_size_custom[1], 3)\n",
        "\n",
        "    # # Convert back to ImageDataGenerator format\n",
        "    # datagen_resampled = ImageDataGenerator(rescale=1/255.0)  # Use the same parameters as before\n",
        "    # train_generator_resampled = datagen_resampled.flow(X_train_resampled, y_train_resampled, batch_size=batch_size)\n",
        "    # val_generator_resampled = datagen_resampled.flow(X_val_resampled, y_val_resampled, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    history=model.fit(train_gen, validation_data=val_gen, batch_size=batch_size, epochs=epochs, callbacks=[rlrp])\n",
        "\n",
        "\n",
        "    #saving model weights and history\n",
        "    model.save(f'{save_checkpoints_path}/model.h5')\n",
        "\n",
        "    hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "    with open(f\"{save_checkpoints_path}/history.json\", \"w\") as outfile:\n",
        "        hist_df.to_json(outfile)\n",
        "\n",
        "\n",
        "    print(\"***Ploting***\")\n",
        "    epochs = [i for i in range(epochs)]\n",
        "    fig , ax = plt.subplots(1,2)\n",
        "    train_acc = history.history['accuracy']\n",
        "    train_loss = history.history['loss']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "    fig.set_size_inches(20,8)\n",
        "    ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
        "    ax[0].plot(epochs , val_loss , label = 'Testing Loss')\n",
        "    ax[0].set_title('Training & Testing Loss')\n",
        "    ax[0].legend()\n",
        "    ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "    ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
        "    ax[1].plot(epochs , val_acc , label = 'Testing Accuracy')\n",
        "    ax[1].set_title('Training & Testing Accuracy')\n",
        "    ax[1].legend()\n",
        "    ax[1].set_xlabel(\"Epochs\")\n",
        "    plt.savefig('train_loss_accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0qzB956uonp"
      },
      "outputs": [],
      "source": [
        "data_path=\"data\"\n",
        "# malevis_data_path=\"malevis_train_val_300x300\"\n",
        "img_path=\"data/malimg_paper_dataset_imgs\"\n",
        "data_csvs=\"data/csvs\"\n",
        "save_checkpoints_path=\"data/checkpoint\"\n",
        "batch_size=28\n",
        "epochs = 15\n",
        "os.makedirs(save_checkpoints_path,exist_ok=True)\n",
        "os.makedirs(data_csvs,exist_ok=True)\n",
        "\n",
        "data_prepare=prepare_data(data_path,img_path,class_index)\n",
        "#combining MalImg and Malevis datasets\n",
        "# data_prepare.combine_datasets(malevis_data_path)\n",
        "if not os.path.exists(f\"{data_csvs}/train.csv\"):\n",
        "    data_prepare.create_csv_data()\n",
        "\n",
        "target_size_custom = (256, 256)\n",
        "input_shape=(256, 256, 3)\n",
        "\n",
        "dataloader=load_data(img_path,data_csvs,target_size_custom,batch_size)\n",
        "train_gen,val_gen=dataloader.train_data()\n",
        "\n",
        "classes = train_gen.class_indices\n",
        "with tensorflow.device('GPU'):\n",
        "  train_gen=train(train_gen,val_gen,target_size_custom,input_shape,save_checkpoints_path,batch_size, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pRi7FsMHGYv"
      },
      "outputs": [],
      "source": [
        "def test(test_gen,save_checkpoints_path):\n",
        "\n",
        "    model=load_model(f\"{save_checkpoints_path}/model.h5\")\n",
        "\n",
        "    y_pred=model.predict(test_gen)\n",
        "    y_test_predicted = np.argmax(np.array(y_pred),axis = 1)\n",
        "    return y_test_predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elPnQszxHGYv"
      },
      "outputs": [],
      "source": [
        "test_gen=dataloader.test_data()\n",
        "y_test_predicted=test(test_gen,save_checkpoints_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kxnpXkDKHrN"
      },
      "outputs": [],
      "source": [
        "y_pred=[]\n",
        "for i in y_test_predicted:\n",
        "  for key,value in class_index.items():\n",
        "    if value==i:\n",
        "      y_pred.append(key)\n",
        "      break\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXuoVAWMEjAW"
      },
      "outputs": [],
      "source": [
        "def confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names,\n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrmVqxrPMUq6"
      },
      "outputs": [],
      "source": [
        "c_matrix = metrics.confusion_matrix(test_gen.classes, y_test_predicted)\n",
        "df_confusion = pd.crosstab(test_gen.classes, y_test_predicted)\n",
        "df_confusion.to_csv(os.path.join(data_path,\"confusion_matrix.csv\"))\n",
        "\n",
        "confusion_matrix(c_matrix, classes, figsize = (20,7), fontsize=14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoGj--lVaW6Q"
      },
      "outputs": [],
      "source": [
        "accuracy=metrics.accuracy_score(test_gen.classes, y_test_predicted)\n",
        "print(\"accuracy\",accuracy)\n",
        "\n",
        "IoU=metrics.jaccard_score(test_gen.classes, y_test_predicted,average=\"micro\")\n",
        "f1=metrics.f1_score(test_gen.classes, y_test_predicted,average=\"micro\")\n",
        "print(\"micro IoU\",IoU)\n",
        "print(\"micro f1\",f1)\n",
        "\n",
        "IoU=metrics.jaccard_score(test_gen.classes, y_test_predicted,average=\"macro\")\n",
        "f1=metrics.f1_score(test_gen.classes, y_test_predicted,average=\"macro\")\n",
        "print(\"macro IoU\",IoU)\n",
        "print(\"macro f1\",f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5T2flBwack9"
      },
      "outputs": [],
      "source": [
        "report = metrics.classification_report(test_gen.classes, y_test_predicted, target_names=classes,  output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "print(df_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzC86zixNY4v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}