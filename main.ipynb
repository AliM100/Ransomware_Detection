{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XXgZ5xpUHLK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/malimg_dataset.zip -d data"
      ],
      "metadata": {
        "id": "wGtwgKseHJif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/Benign/\" \"/content/data/malimg_paper_dataset_imgs\""
      ],
      "metadata": {
        "id": "3qO82vGtHn6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doyaiCPqHGYt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import os\n",
        "from math import log\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import dataset\n",
        "from dataset import load_data\n",
        "from model import get_model\n",
        "import tensorflow\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxKqkHzeHGYu"
      },
      "outputs": [],
      "source": [
        "def train(dataloader,target_size_custom,save_checkpoints_path,batch_size, epochs):\n",
        "\n",
        "    train_gen,val_gen=dataloader.train_data()\n",
        "    with tensorflow.device('GPU'):\n",
        "        model = get_model(target_size_custom)\n",
        "\n",
        "        rlrp = ReduceLROnPlateau(monitor='loss', factor=0.2, verbose=1, patience=5, min_lr=0.000001) #\n",
        "\n",
        "        history=model.fit(train_gen, validation_data=val_gen, batch_size=batch_size, epochs=epochs, callbacks=[rlrp])\n",
        "\n",
        "        #saving model weights and history\n",
        "        model.save(f'{save_checkpoints_path}/model.h5')\n",
        "\n",
        "        hist_df = pd.DataFrame(history.history)\n",
        "\n",
        "        with open(f\"{save_checkpoints_path}/history.json\", \"w\") as outfile:\n",
        "            hist_df.to_json(outfile)\n",
        "\n",
        "\n",
        "        print(\"***Ploting***\")\n",
        "        epochs = [i for i in range(epochs)]\n",
        "        fig , ax = plt.subplots(1,2)\n",
        "        train_acc = history.history['accuracy']\n",
        "        train_loss = history.history['loss']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "        val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "        fig.set_size_inches(20,8)\n",
        "        ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
        "        ax[0].plot(epochs , val_loss , label = 'Testing Loss')\n",
        "        ax[0].set_title('Training & Testing Loss')\n",
        "        ax[0].legend()\n",
        "        ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "        ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
        "        ax[1].plot(epochs , val_acc , label = 'Testing Accuracy')\n",
        "        ax[1].set_title('Training & Testing Accuracy')\n",
        "        ax[1].legend()\n",
        "        ax[1].set_xlabel(\"Epochs\")\n",
        "        plt.savefig('train_loss_accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pRi7FsMHGYv"
      },
      "outputs": [],
      "source": [
        "def test(dataloader,save_checkpoints_path):\n",
        "\n",
        "    test_gen=dataloader.test_data()\n",
        "\n",
        "    model=load_model(f\"{save_checkpoints_path}/model.h5\")\n",
        "\n",
        "\n",
        "    pred=model.predict(test_gen)\n",
        "\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pusF2bfVHGYv"
      },
      "outputs": [],
      "source": [
        "gpus = tensorflow.config.list_physical_devices('GPU')\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvHpDP5fHGYv"
      },
      "outputs": [],
      "source": [
        "data_path=\"data\"\n",
        "img_path=\"data/malimg_paper_dataset_imgs\"\n",
        "data_csvs=\"data/csvs\"\n",
        "save_checkpoints_path=\"data/checkpoint\"\n",
        "batch_size=28\n",
        "epochs = 10\n",
        "os.makedirs(save_checkpoints_path,exist_ok=True)\n",
        "os.makedirs(data_csvs,exist_ok=True)\n",
        "\n",
        "if not os.path.exists(f\"{data_csvs}/train.csv\"):\n",
        "    dataset.create_csv_data(data_path,img_path)\n",
        "\n",
        "target_size_custom = (256, 256)\n",
        "\n",
        "\n",
        "dataloader=load_data(img_path,data_csvs,target_size_custom,batch_size)\n",
        "\n",
        "train(dataloader,target_size_custom,save_checkpoints_path,batch_size, epochs)\n",
        "\n",
        "# test(dataloader,target_size_custom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elPnQszxHGYv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}